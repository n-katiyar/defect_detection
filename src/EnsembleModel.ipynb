{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ../input/pretrainedmodels-new2/pretrainedmodels-0.7.4/ > /dev/null\n!pip install ../input/efficientnet-pytorch/ > /dev/null\n!pip install ../input/timm-pytorch-image-models/pytorch-image-models-master/ > /dev/null\n!pip install ../input/segmodelqubvel/segmentation_models.pytorch-master/ > /dev/null\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"package_path = '../input/segmodelqubvel/segmentation_models.pytorch-master/segmentation_models_pytorch' # add unet script dataset\nimport sys\nsys.path.append(package_path)\nfrom segmentation_models_pytorch import Unet, FPN, DeepLabV3Plus","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pdb\nimport os\nimport cv2\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset\nfrom albumentations import (Normalize, Compose)\nfrom albumentations.pytorch import ToTensor\nimport torch.utils.data as data\n#from model import Unet\nimport glob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Model with best score\n\nckpt_path = \"../input/models-steel-1/unet_seresnet50_bce.pth\"\ndevice = torch.device(\"cuda\")\nmodel = Unet(\"se_resnet50\", encoder_weights=None, classes=4, activation=None)\nmodel.to(device)\nmodel.eval()\nstate = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\nmodel.load_state_dict(state[\"state_dict\"])\nmodels.append(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Model with 2nd best score\n\nckpt_path = \"../input/models-steel-1/fpn_efficientnetb3_bce.pth\"\ndevice = torch.device(\"cuda\")\nmodel = FPN(\"efficientnet-b3\", encoder_weights=None, classes=4, activation=None)\nmodel.to(device)\nmodel.eval()\nstate = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\nmodel.load_state_dict(state[\"state_dict\"])\nmodels.append(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Model with 3rd best score\n\nckpt_path = \"../input/models-steel-1/fpn_efficientnet_b1.pth\"\ndevice = torch.device(\"cuda\")\nmodel = FPN(\"efficientnet-b1\", encoder_weights=None, classes=4, activation=None)\nmodel.to(device)\nmodel.eval()\nstate = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\nmodel.load_state_dict(state[\"state_dict\"])\nmodels.append(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Model with 4th best score\n'''\nckpt_path = \"../input/models-steel-1/deeplabv3plus_resnet34_bce.pth\"\ndevice = torch.device(\"cuda\")\nmodel = DeepLabV3Plus(\"resnet34\", encoder_weights=None, classes=4, activation=None)\nmodel.to(device)\nmodel.eval()\nstate = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\nmodel.load_state_dict(state[\"state_dict\"])\nmodels.append(model)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Model with 5th best score\n\nckpt_path = \"../input/models-steel-1/fpn_resnet34_bce.pth\"\ndevice = torch.device(\"cuda\")\nmodel = FPN(\"resnet34\", encoder_weights=None, classes=4, activation=None)\nmodel.to(device)\nmodel.eval()\nstate = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\nmodel.load_state_dict(state[\"state_dict\"])\nmodels.append(model)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Model with 6th best score\n'''\nckpt_path = \"../input/models-steel-1/unet_se_resnext_bce.pth\"\ndevice = torch.device(\"cuda\")\nmodel = Unet(\"se_resnext50_32x4d\", encoder_weights=None, classes=4, activation=None)\nmodel.to(device)\nmodel.eval()\nstate = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\nmodel.load_state_dict(state[\"state_dict\"])\nmodels.append(model)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_names=[]\nfor file in glob.glob(\"../input/severstal-steel-defect-detection/test_images/*.jpg\"):\n    test_image_names.append(file.split('/')[-1])\nsorted(test_image_names)\n#test_image_names=test_image_names[:8]\nprint(test_image_names[:5])\nprint(len(test_image_names))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    '''Dataset for test prediction'''\n    def __init__(self, root, df, mean, std,test_idx):\n        self.root = root\n        #df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n        #self.fnames = df['ImageId'].unique().tolist()\n        self.fnames=test_idx\n        self.num_samples = len(self.fnames)\n        self.transform = Compose(\n            [\n                Normalize(mean=mean, std=std, p=1),\n                ToTensor(),\n            ]\n        )\n\n    def __getitem__(self, idx):\n        fname = self.fnames[idx]\n        path = os.path.join(self.root, fname)\n        image = cv2.imread(path)\n        images = self.transform(image=image)[\"image\"]\n        return fname, images\n\n    def __len__(self):\n        return self.num_samples","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def post_process(probability, threshold, min_size):\n    '''Post processing of each predicted mask, components with lesser number of pixels\n    than `min_size` are ignored'''\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros((256, 1600), np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n    return predictions, num","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission_path = '../input/severstal-steel-defect-detection/sample_submission.csv'\ntest_data_folder = \"../input/severstal-steel-defect-detection/test_images\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_threshold = [0.5,0.6,0.45,0.4]\nnum_workers = 2\nbatch_size = 1\nprint('best_threshold', best_threshold)\nmin_size = [1400,1800,1200,1300]\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\ndf = pd.read_csv(sample_submission_path)\ntestset = DataLoader(\n    TestDataset(test_data_folder, df, mean, std,test_image_names),\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    pin_memory=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor i, batch in enumerate(tqdm(testset)):\n    fnames, images = batch\n    images=images.to(device)\n    batch_preds=torch.zeros((len(fnames),4,256,1600)).to(device)\n    num_aug=0\n    for i in range(len(models)):\n        if 1:\n            batch_preds += torch.sigmoid(models[i](images))\n            num_aug += 1\n        if 1:\n            batch_preds += torch.flip(torch.sigmoid(models[i](torch.flip(images,dims=[2]))),dims=[2])\n            num_aug += 1\n        if 1:\n            batch_preds += torch.flip(torch.sigmoid(models[i](torch.flip(images,dims=[3]))),dims=[3])\n            num_aug += 1\n    \n    batch_preds = batch_preds.detach().cpu().numpy()/(num_aug)\n    #print(num_aug)\n    for fname, preds in zip(fnames, batch_preds):\n        for cls, pred in enumerate(preds):\n            pred, num = post_process(pred, best_threshold[cls], min_size[cls])\n            rle = mask2rle(pred)\n            name = fname + f\"_{cls+1}\"\n            predictions.append([name, rle])\n\n# save predictions to submission.csv\ndf = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\ndf.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_aug","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}